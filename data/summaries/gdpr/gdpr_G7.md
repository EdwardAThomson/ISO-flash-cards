# G7: Special Categories & High‑Risk Processing

## Special Categories of Personal Data (Article 9)

Special categories are particularly **sensitive** and require additional protection. They include data revealing:
- Racial or ethnic origin
- Political opinions
- Religious or philosophical beliefs
- Trade union membership
- Genetic data
- Biometric data for the purpose of uniquely identifying a natural person
- Data concerning health
- Data concerning a natural person’s sex life or sexual orientation

### General Rule

Processing these data is **prohibited**, unless an **Article 9(2) condition** applies **and** there is a valid Article 6 legal basis.

### Common Article 9 Conditions

- **Explicit consent**
- **Employment, social security and social protection law**
- **Vital interests** where person is incapable of consent
- **Non‑profit bodies** with appropriate safeguards
- **Data made public** by the data subject
- **Legal claims**
- **Substantial public interest** (based on EU or Member State law)
- **Healthcare and public health** purposes
- **Archiving, research, statistics** with safeguards

---

## Criminal Convictions and Offences (Article 10)

Data relating to criminal convictions and offences require **separate safeguards** and may be processed only:
- Under control of official authority, or
- When authorized by EU or Member State law with appropriate safeguards.

---

## High‑Risk Processing and DPIAs

### High‑Risk Indicators

Processing is more likely to be **high risk** when it involves:
- Systematic and extensive profiling with significant effects
- Large‑scale processing of special categories
- Large‑scale systematic monitoring of a publicly accessible area
- Innovative technologies
- Matching or combining datasets
- Data of vulnerable individuals (e.g., children, patients)

When high risk is likely, a **DPIA is required** (see G3 for DPIA process).

### Example High‑Risk Scenarios

- Hospital processing large volumes of patient health data
- Bank using automated credit scoring affecting loan decisions
- Behavioral advertising using extensive profiling
- Facial recognition in public spaces

---

## Safeguards for High‑Risk Processing

Examples of safeguards include:
- Strong access controls and role‑based access
- Encryption and pseudonymization
- Data minimization and strict retention limits
- Regular security testing and audits
- Human review of automated decisions
- Enhanced transparency and notices
- Regular DPIA reviews and updates

---

## Children’s Data

Children merit **specific protection**, especially regarding marketing, profiling, and online services.

- Age of consent for information society services often **16 or lower**, depending on Member State (usually 13–16)
- Parental consent may be required in some contexts
- Language in notices must be clear and age‑appropriate

---

## Research, Archiving and Statistics

GDPR allows some **flexibilities** for processing for archiving in the public interest, scientific or historical research, and statistical purposes, subject to safeguards such as:
- Pseudonymization
- Data minimization
- Technical and organizational measures to protect rights

These activities often still require DPIAs and careful governance.

---

## Key Takeaways

1. Special categories and criminal data require **stricter conditions** and safeguards.
2. Many high‑risk scenarios trigger **DPIA requirements**.
3. Children’s data needs **extra protection and clearer transparency**.
4. Research and public interest uses can be enabled with **strong safeguards**.
5. High‑risk processing must be **carefully designed, justified, and documented**.
