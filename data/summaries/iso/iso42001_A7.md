# A7: Oversight & Incidents

## Human Oversight

Human oversight is a critical element of responsible AI. ISO 42001 addresses oversight through multiple controls.

### A.9.3 Human Oversight

**Control:** Appropriate human oversight of AI systems shall be determined and implemented.

### Levels of Human Oversight

| Level | Description | Example |
|-------|-------------|---------|
| **Human-in-the-loop** | Human approves every AI decision | Medical diagnosis confirmation |
| **Human-on-the-loop** | Human monitors and can intervene | Autonomous vehicle supervision |
| **Human-in-command** | Human sets parameters, AI operates within bounds | Trading system limits |
| **Full automation** | No human involvement in decisions | Spam filtering |

### Determining Appropriate Oversight

Consider:
- **Risk level** — Higher risk requires more oversight
- **Reversibility** — Irreversible decisions need more review
- **Impact** — Significant impacts warrant human involvement
- **Regulatory requirements** — Some decisions require human review
- **Stakeholder expectations** — What do affected parties expect?

### Implementing Oversight

| Element | Implementation |
|---------|----------------|
| **Roles** | Define who provides oversight |
| **Training** | Ensure overseers understand the AI system |
| **Tools** | Provide interfaces for monitoring and intervention |
| **Authority** | Empower overseers to override or stop AI |
| **Time** | Allow adequate time for meaningful review |
| **Escalation** | Define when to escalate decisions |

---

## Transparency and Communication

### A.8.2 Information for Interested Parties

**Control:** Information about AI systems shall be provided to interested parties.

**Information to provide:**

| Audience | Information Needs |
|----------|-------------------|
| **Users** | How to use, capabilities, limitations |
| **Affected individuals** | That AI is being used, how it affects them |
| **Regulators** | Compliance documentation |
| **Partners** | Integration requirements, responsibilities |

### A.8.3 External Communication

**Control:** External communications about AI systems shall be managed.

**Communication considerations:**
- Accuracy of claims about AI capabilities
- Transparency about AI use
- Accessibility of information
- Timeliness of updates

### A.8.4 Reporting AI System Behavior

**Control:** A process for reporting AI system behavior shall be established.

**Reporting mechanisms:**
- Internal reporting channels
- External feedback mechanisms
- Incident reporting systems
- Whistleblower protections

---

## Incident Management

### Defining AI Incidents

An AI incident is an event where an AI system:
- Causes or nearly causes harm
- Fails to perform as intended
- Produces unexpected or undesirable outputs
- Violates policies or regulations

### Incident Categories

| Category | Examples |
|----------|----------|
| **Safety incidents** | Physical harm, health impacts |
| **Fairness incidents** | Discriminatory outcomes |
| **Privacy incidents** | Data breaches, unauthorized inference |
| **Security incidents** | Adversarial attacks, unauthorized access |
| **Performance incidents** | Accuracy degradation, system failures |
| **Compliance incidents** | Regulatory violations |

### Incident Response Process

```
┌─────────────────────────────────────────────────────────┐
│              INCIDENT RESPONSE PROCESS                   │
├─────────────────────────────────────────────────────────┤
│                                                         │
│  ┌──────────┐   ┌──────────┐   ┌──────────┐           │
│  │  Detect  │──▶│  Assess  │──▶│ Contain  │           │
│  └──────────┘   └──────────┘   └────┬─────┘           │
│                                      │                 │
│                                      ▼                 │
│  ┌──────────┐   ┌──────────┐   ┌──────────┐           │
│  │  Learn   │◀──│ Recover  │◀──│Investigate│          │
│  └──────────┘   └──────────┘   └──────────┘           │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

### Incident Response Steps

| Step | Activities |
|------|------------|
| **Detect** | Identify that an incident has occurred |
| **Assess** | Determine severity, scope, and urgency |
| **Contain** | Limit further harm or damage |
| **Investigate** | Determine root cause |
| **Recover** | Restore normal operations |
| **Learn** | Document lessons, improve processes |

### Incident Documentation

Document for each incident:
- Date and time of occurrence and detection
- Description of the incident
- AI system(s) involved
- Impact assessment
- Containment actions taken
- Root cause analysis
- Corrective actions
- Lessons learned

---

## Nonconformity and Corrective Action (Clause 10.1)

### Responding to Nonconformity

When a nonconformity occurs, the organization must:

1. **React** — Take action to control and correct it
2. **Evaluate** — Determine if action is needed to eliminate causes
3. **Implement** — Take corrective action as needed
4. **Review** — Assess effectiveness of corrective action
5. **Update** — Modify the AIMS if necessary

### Root Cause Analysis

Techniques for identifying root causes:

| Technique | Description |
|-----------|-------------|
| **5 Whys** | Ask "why" repeatedly to find root cause |
| **Fishbone diagram** | Categorize potential causes |
| **Fault tree analysis** | Map causal relationships |
| **Pareto analysis** | Identify most significant causes |

### Corrective Action

Corrective actions should:
- Address the root cause, not just symptoms
- Be proportionate to the impact
- Prevent recurrence
- Be documented and tracked
- Be verified for effectiveness

---

## Monitoring and Measurement (Clause 9.1)

### What to Monitor

| Area | Metrics |
|------|---------|
| **AIMS effectiveness** | Objective achievement, control effectiveness |
| **AI system performance** | Accuracy, fairness, reliability |
| **Incidents** | Number, severity, response time |
| **Compliance** | Audit findings, regulatory issues |
| **Stakeholder satisfaction** | Feedback, complaints |

### Monitoring Methods

- Automated monitoring systems
- Periodic assessments
- Internal audits
- Management reviews
- Stakeholder feedback

---

## Internal Audit (Clause 9.2)

### Audit Requirements

Organizations must conduct internal audits at planned intervals to determine if the AIMS:
- Conforms to requirements (ISO 42001 and organization's own)
- Is effectively implemented and maintained

### Audit Process

1. **Plan** — Define audit program, criteria, scope
2. **Prepare** — Develop audit plan, checklists
3. **Execute** — Conduct audit, gather evidence
4. **Report** — Document findings, conclusions
5. **Follow up** — Track corrective actions

### Auditor Requirements

- Objectivity and impartiality
- Competence in auditing and AI
- Independence from audited area

---

## Management Review (Clause 9.3)

### Review Requirements

Top management must review the AIMS at planned intervals to ensure:
- Continuing suitability
- Adequacy
- Effectiveness

### Review Inputs

- Status of previous review actions
- Changes in context and stakeholder needs
- AIMS performance (nonconformities, audit results, objectives)
- Feedback from interested parties
- Risk assessment results
- Opportunities for improvement

### Review Outputs

- Improvement opportunities
- Changes needed to the AIMS
- Resource needs

---

## Key Takeaways

1. **Human oversight** — Appropriate level based on risk and impact
2. **Transparency** — Communicate clearly with stakeholders
3. **Incident management** — Prepare for and learn from incidents
4. **Corrective action** — Address root causes, not just symptoms
5. **Continuous monitoring** — Track performance and compliance
6. **Regular review** — Management must assess AIMS effectiveness
