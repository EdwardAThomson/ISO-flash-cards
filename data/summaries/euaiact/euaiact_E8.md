# E8: Timeline & Compliance

The EU AI Act has a **phased implementation** timeline, giving organizations time to prepare for different requirements.

## Key Dates

| Date | What Happens |
|------|--------------|
| **August 1, 2024** | Act enters into force (20 days after publication) |
| **February 2, 2025** | Prohibited AI practices banned |
| **August 2, 2025** | GPAI model rules apply; Codes of Practice due |
| **August 2, 2026** | Full application — all other provisions, including high-risk requirements |
| **August 2, 2027** | High-risk AI in Annex I products (certain regulated products) |

---

## Compliance Roadmap

### Phase 1: Immediate (Now – February 2025)

**Priority actions:**
- [ ] **Inventory** all AI systems in use and development
- [ ] **Classify** systems by risk level
- [ ] **Identify prohibited practices** and plan phase-out
- [ ] **Establish governance** structure for AI oversight
- [ ] **Train staff** on EU AI Act basics

### Phase 2: Prohibited Practices (February 2025)

**Must be compliant with:**
- No social scoring systems
- No manipulative/deceptive AI
- No exploitation of vulnerabilities
- No untargeted facial recognition scraping
- No emotion recognition in workplace/education (unless exempted)
- No biometric categorization for sensitive attributes
- No real-time RBI in public spaces (unless exempted)

### Phase 3: GPAI Rules (August 2025)

**GPAI providers must:**
- [ ] Prepare technical documentation
- [ ] Publish training data summary
- [ ] Implement copyright compliance policy
- [ ] Provide information to downstream providers
- [ ] (If systemic risk) Conduct evaluations, assess risks, report incidents

### Phase 4: Full Application (August 2026)

**High-risk AI providers must:**
- [ ] Implement risk management system
- [ ] Establish data governance practices
- [ ] Prepare technical documentation
- [ ] Enable logging capabilities
- [ ] Ensure transparency and user information
- [ ] Design for human oversight
- [ ] Meet accuracy, robustness, cybersecurity standards
- [ ] Complete conformity assessment
- [ ] Register in EU database
- [ ] Affix CE marking

**High-risk AI deployers must:**
- [ ] Use systems according to instructions
- [ ] Assign human oversight
- [ ] Monitor system operation
- [ ] Keep logs (where under their control)
- [ ] Conduct fundamental rights impact assessment (if required)
- [ ] Inform affected persons (where required)

---

## Transitional Provisions

### Existing AI Systems

**High-risk AI systems already on the market before August 2026:**
- May continue to be used
- Must comply if **significantly modified**
- Operators of GPAI-based systems have until **August 2027** to comply

### Existing GPAI Models

**GPAI models already on the market before August 2025:**
- Must comply with GPAI rules by **August 2027**
- Unless significantly modified earlier

### Public Authority Systems

**High-risk AI used by public authorities:**
- Must comply by **August 2030** if placed on market before August 2026
- Earlier compliance required for new procurements

---

## Compliance Strategies

### For Providers

1. **Gap analysis** — Compare current practices against requirements
2. **Documentation** — Start building technical documentation early
3. **Quality management** — Implement or enhance QMS for AI
4. **Testing regime** — Establish evaluation and testing procedures
5. **Conformity pathway** — Determine self-assessment vs. third-party
6. **Monitoring** — Set up post-market monitoring processes

### For Deployers

1. **Vendor assessment** — Evaluate AI providers for compliance readiness
2. **Use case review** — Ensure intended use aligns with provider documentation
3. **Human oversight** — Designate and train oversight personnel
4. **Impact assessment** — Conduct fundamental rights assessments where required
5. **Incident procedures** — Establish reporting mechanisms

### For Both

1. **Stay informed** — Monitor guidance from AI Office and national authorities
2. **Engage with standards** — Follow harmonized standards development
3. **Join industry groups** — Participate in codes of practice development
4. **Document decisions** — Maintain records of compliance reasoning

---

## Resources

### Official Sources
- **EUR-Lex** — Full text of the regulation
- **AI Office** — Guidance and updates
- **National authorities** — Country-specific implementation

### Standards Development
- **CEN/CENELEC** — Developing harmonized standards
- **ISO/IEC** — International AI standards (42001, etc.)

### Support for SMEs
- **AI regulatory sandboxes** — Test innovations with regulatory support
- **Real-world testing** — Controlled testing provisions
- **Reduced fees** — Lower conformity assessment costs for SMEs

---

## Key Takeaways

1. **Start now** — Compliance requires significant preparation
2. **Risk-based approach** — Focus resources on highest-risk systems first
3. **Documentation is critical** — Build records throughout development
4. **Human oversight** — Design for meaningful human control from the start
5. **Monitor developments** — Guidance and standards continue to evolve
