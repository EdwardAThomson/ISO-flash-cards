# E3: Prohibited AI Practices

The EU AI Act **bans outright** certain AI practices considered to pose an unacceptable risk to fundamental rights and safety. These prohibitions apply from **February 2025**.

## Prohibited Practices

### 1. Manipulative & Deceptive AI
AI systems that deploy **subliminal, manipulative, or deceptive techniques** to:
- Materially distort behavior
- Impair informed decision-making
- Cause significant harm

This includes techniques beyond a person's consciousness or exploiting vulnerabilities.

### 2. Exploitation of Vulnerabilities
AI systems that exploit vulnerabilities due to:
- **Age** (children, elderly)
- **Disability**
- **Social or economic situation**

...in ways that materially distort behavior and cause or are likely to cause significant harm.

### 3. Social Scoring
AI systems used by **public authorities** (or on their behalf) for:
- Evaluating or classifying people based on social behavior or personal characteristics
- Leading to **detrimental treatment** that is:
  - Unjustified or disproportionate to the behavior, OR
  - In unrelated contexts, OR
  - Disproportionate to the gravity of the behavior

### 4. Criminal Risk Assessment (Solely Based on Profiling)
AI systems that assess the risk of a person committing a criminal offense **based solely on**:
- Profiling, OR
- Personality traits and characteristics

**Exception**: AI that supports human assessment based on objective, verifiable facts directly linked to criminal activity.

### 5. Facial Recognition Database Scraping
AI systems that create or expand facial recognition databases through **untargeted scraping** of facial images from:
- The internet
- CCTV footage

### 6. Emotion Recognition in Workplace & Education
AI systems that infer emotions in:
- **Workplace** settings
- **Educational institutions**

**Exceptions**: Systems for medical or safety purposes (e.g., monitoring pilot fatigue).

### 7. Biometric Categorization for Sensitive Attributes
AI systems that categorize people based on biometric data to **deduce or infer**:
- Race or ethnic origin
- Political opinions
- Trade union membership
- Religious or philosophical beliefs
- Sex life or sexual orientation

**Exception**: Labeling or filtering of lawfully acquired biometric datasets (e.g., for law enforcement).

### 8. Real-Time Remote Biometric Identification (RBI) in Public Spaces

AI systems for **real-time** remote biometric identification in **publicly accessible spaces** for **law enforcement**.

#### Exceptions (Strictly Necessary For):

| Purpose | Conditions |
|---------|------------|
| **Targeted victim search** | Missing persons, trafficking victims, abduction victims | 
| **Preventing imminent threat** | Specific, substantial threat to life or terrorist attack |
| **Locating/identifying suspects** | Serious criminal offenses (listed in Framework Decision) |

#### Safeguards for Exceptions:
- Prior **judicial or independent administrative authorization** (except in duly justified urgency)
- Limited in **time, geography, and persons** searched
- **Fundamental rights impact assessment** completed
- Registered in **EU database** (except for urgency)
- Notification to **market surveillance authority** and **data protection authority**

## Key Points

- Prohibitions apply to **all actors** (providers, deployers, etc.)
- No exceptions for private sector social scoring
- "Significant harm" includes physical, psychological, financial, and societal harm
- Violations carry the **highest penalties**: up to â‚¬35M or 7% of global turnover
