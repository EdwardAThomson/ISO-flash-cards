# E5: Transparency Requirements (Limited Risk)

Certain AI systems have **transparency obligations** even if they're not classified as high-risk. These requirements ensure people know when they're interacting with AI or AI-generated content.

## Systems with Transparency Obligations

### 1. AI Systems Interacting with People

AI systems intended to **directly interact with natural persons** must inform users that they are interacting with an AI system.

**Exception**: Where this is obvious from the circumstances and context of use (e.g., clearly robotic voice assistants).

This applies to systems like:
- Chatbots
- Virtual assistants
- AI customer service agents
- AI-powered phone systems

### 2. Emotion Recognition Systems

Deployers of **emotion recognition systems** must inform exposed persons that such a system is being used.

This applies when the system is:
- Not prohibited (i.e., not in workplace/education without medical/safety purpose)
- Used in contexts where disclosure is required

### 3. Biometric Categorization Systems

Deployers of **biometric categorization systems** must inform exposed persons that such a system is being used.

This includes systems that categorize people based on biometric data into groups based on:
- Gender
- Age
- Hair color
- Eye color
- Tattoos
- Ethnic origin (where not prohibited)

### 4. AI-Generated or Manipulated Content ("Deepfakes")

Providers and deployers of AI systems that generate or manipulate:
- **Image content**
- **Audio content**
- **Video content**

...that constitutes a **"deep fake"** must disclose that the content has been artificially generated or manipulated.

#### What is a Deep Fake?
AI-generated or manipulated content that:
- Depicts a person appearing to say or do something they did not say or do
- Resembles existing persons, objects, places, or events
- Would falsely appear to be authentic or truthful

#### Labeling Requirements
Content must be:
- Marked in a **machine-readable format**
- **Detectable** as artificially generated or manipulated
- Labeled in a way that is **effective, accessible, and visible**

### 5. AI-Generated Text on Public Interest Matters

AI-generated text that is published to **inform the public on matters of public interest** must be labeled as artificially generated.

**Exception**: Where the content has undergone human editorial review and a natural or legal person holds editorial responsibility.

---

## How to Comply

### For Providers
- Design systems to enable transparency disclosures
- Provide deployers with information needed for compliance
- Implement machine-readable labeling for synthetic content

### For Deployers
- Display clear notices before or during AI interaction
- Ensure disclosures are:
  - **Clear and distinguishable**
  - **Provided at the latest at first interaction**
  - **Accessible** (consider different user needs)

---

## Exceptions to Transparency Requirements

Transparency obligations **do not apply** when:

1. AI systems are **authorized by law** for:
   - Detection, prevention, investigation, or prosecution of criminal offenses
   - Subject to appropriate safeguards for rights and freedoms

2. Content is part of an **obviously artistic, creative, satirical, or fictional** work
   - But must not affect rights of third parties

3. Disclosure would **undermine legitimate law enforcement** purposes

---

## Key Points

- Transparency requirements apply **regardless of risk classification**
- Focus is on **user awareness** and **informed decision-making**
- Machine-readable labeling enables **downstream detection**
- Penalties for non-compliance: up to â‚¬15M or 3% of global turnover
